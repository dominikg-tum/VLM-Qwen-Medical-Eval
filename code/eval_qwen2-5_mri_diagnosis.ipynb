{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952f7945",
   "metadata": {},
   "source": [
    "# ðŸ§  Qwen2.5 Brain MRI Disease Diagnosis\n",
    "\n",
    "Predict disease based on clinical history and image findings using Qwen2.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d812b4",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2454d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "DATASET_DIR = \"VLM-Seminar25-Dataset/nova_brain\"\n",
    "ANNOT_PATH = os.path.join(DATASET_DIR, \"annotations.json\")\n",
    "RESULTS_DIR = \"../results/nova_brain\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "with open(ANNOT_PATH, \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "case_ids = list(annotations.keys())\n",
    "\n",
    "load_dotenv(dotenv_path=\"config/user.env\")\n",
    "api_key = os.environ.get(\"NEBIUS_API_KEY\")\n",
    "client = OpenAI(base_url=\"https://api.studio.nebius.com/v1/\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_new_inference = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b8fcb",
   "metadata": {},
   "source": [
    "## 2. Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_results = []\n",
    "if do_new_inference:\n",
    "    for case_id in tqdm(case_ids):\n",
    "        case = annotations[case_id]\n",
    "        clinical_history = case.get(\"clinical_history\", \"\")\n",
    "        findings = []\n",
    "        for img_name, img_info in case.get(\"image_findings\", {}).items():\n",
    "            findings.append(f\"{img_name}: {img_info.get('caption', '')}\")\n",
    "        findings_str = \" \".join(findings)\n",
    "        prompt = f\"Based on the clinical history: {clinical_history} and image findings: {findings_str}, provide your diagnosis for the disease.\"\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"Qwen/Qwen2.5-VL-72B-Instruct\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt}\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "        pred = completion.choices[0].message.content.strip()\n",
    "        diagnosis_results.append({\n",
    "            \"case_id\": case_id,\n",
    "            \"prediction\": pred,\n",
    "            \"ground_truth\": case.get(\"final_diagnosis\", \"\")\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a08560",
   "metadata": {},
   "source": [
    "## 3. Save Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_DIR, \"qwen2.5_diagnosis_results.json\"), \"w\") as f:\n",
    "    json.dump(diagnosis_results, f, indent=2)\n",
    "print(\"Saved diagnosis results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e59d8e",
   "metadata": {},
   "source": [
    "Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULTS_DIR, \"qwen2.5_diagnosis_results.json\"), \"r\") as f:\n",
    "    diagnosis_results = json.load(f)\n",
    "print(f\"Number of cases diagnosed: {len(diagnosis_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396d313c",
   "metadata": {},
   "source": [
    "## 4. Evaluation & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22098215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally import from /code/eval_scripts/ if available\n",
    "# from eval_scripts.diagnosis_eval import compute_metrics\n",
    "\n",
    "gt = [x[\"ground_truth\"] for x in diagnosis_results]\n",
    "pred = [x[\"prediction\"] for x in diagnosis_results]\n",
    "\n",
    "# Dummy accuracy: exact string match (replace with your own metric if needed)\n",
    "correct = sum([g.strip().lower() == p.strip().lower() for g, p in zip(gt, pred)])\n",
    "accuracy = correct / len(gt) if gt else 0.0\n",
    "\n",
    "eval_metrics = {\"accuracy\": accuracy}\n",
    "with open(os.path.join(RESULTS_DIR, \"diagnosis_eval_metrics.json\"), \"w\") as f:\n",
    "    json.dump(eval_metrics, f, indent=2)\n",
    "print(\"Saved evaluation metrics.\")\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.bar([\"Accuracy\"], [accuracy], color=\"cornflowerblue\")\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Qwen2.5 MRI Diagnosis Accuracy\")\n",
    "plt.text(0, accuracy + 0.02, f\"{accuracy:.2f}\", ha='center', fontsize=12)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"diagnosis_metrics.png\"))\n",
    "plt.show()\n",
    "plt.close()\n",
    "print(\"Saved accuracy plot.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
