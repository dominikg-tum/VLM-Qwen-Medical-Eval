{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0750ef0a",
   "metadata": {},
   "source": [
    "# Qwen2.5 Quick API Test & Data Loading\n",
    "\n",
    "This notebook demonstrates basic Qwen2.5 API usage and dataset loading for the seminar.  \n",
    "**For full evaluation and reproducible experiments, use the dedicated task-specific notebooks:**\n",
    "- Chest X-ray: Classification, Grounding\n",
    "- Brain MRI: Description, Detection, Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23fcf2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# Try loading both .env and user.env for compatibility\n",
    "load_dotenv(dotenv_path=\"../config/user.env\")\n",
    "\n",
    "api_key = os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"WARNING: OPENROUTER_API_KEY is not set or not loaded from env file.\")\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed49fe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is classified as 'unhealthy'. The X-ray shows a chest that has undergone surgery, indicated by the presence of surgical clips and possibly a drain. These features suggest a recent intervention, which typically follows from an unhealthy condition that required treatment. Additionally, the texture and appearance of the surrounding tissues and organs may also show signs of illness or recovery that would not be present in a healthy chest X-ray.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "# Function to get base64 string from a local file\n",
    "def encode_image_to_data_uri(path: str) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "    return f\"data:image/png;base64,{b64}\"\n",
    "\n",
    "# Use local PNG file\n",
    "data_uri = encode_image_to_data_uri(\"VLM-Seminar25-Dataset/chest_xrays/images/0cbaca12e05803e6301f8f4a92b47565.png\")\n",
    " \n",
    "completion = client.chat.completions.create(\n",
    "\n",
    "    model=\"qwen/qwen2.5-vl-72b-instruct:free\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Given the medical image, classify it as 'healthy' or 'unhealthy'. It is very important that you only output only either 'healthy' or 'unhealthy'.\"},  \n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test load data \n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ====== Configuration ======\n",
    "FOLDER = 'VLM-Seminar25-Dataset/chest_xrays'\n",
    "ANNOTATIONS_PATH = os.path.join(FOLDER, 'annotations_len_50.json')\n",
    "IMAGES_PATH = os.path.join(FOLDER, 'images')\n",
    "FONT_PATH = \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\"  # fallback to default if not found\n",
    "FONT_SIZE = 32\n",
    "FIG_SIZE = (10, 5)\n",
    "BASE_COLORS = ['#ff9999','#99ccff','#99ff99','#ffcc99','#cc99ff','#99ffff','#ff99ff','#ffff99']\n",
    "\n",
    "# ====== Helper Functions ======\n",
    "def draw_text(draw, pos, text, font, color, outline=2):\n",
    "    for dx in [-outline, outline]:\n",
    "        for dy in [-outline, outline]:\n",
    "            draw.text((pos[0]+dx, pos[1]+dy), text, font=font, fill='black')\n",
    "    draw.text(pos, text, font=font, fill=color)\n",
    "\n",
    "def get_color(label, color_map):\n",
    "    if label not in color_map:\n",
    "        if len(color_map) < len(BASE_COLORS):\n",
    "            color_map[label] = BASE_COLORS[len(color_map)]\n",
    "        else:\n",
    "            color_map[label] = tuple(np.random.rand(3,))\n",
    "    return color_map[label]\n",
    "\n",
    "def visualize_sample(img_id, ann, color_map):\n",
    "    img_file = os.path.join(IMAGES_PATH, img_id + '.png')\n",
    "    if not os.path.exists(img_file):\n",
    "        print(f\"Image not found: {img_file}\")\n",
    "        return None\n",
    "    \n",
    "    img = Image.open(img_file).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(FONT_PATH, FONT_SIZE)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for x1, y1, x2, y2, label in ann.get('bbox_2d', []):\n",
    "        color = get_color(label, color_map)\n",
    "        for w in range(6):\n",
    "            draw.rectangle([x1-w, y1-w, x2+w, y2+w], outline=color)\n",
    "        bbox_text = draw.textbbox((0,0), label, font=font)\n",
    "        text_w = bbox_text[2] - bbox_text[0]\n",
    "        text_h = bbox_text[3] - bbox_text[1]\n",
    "        text_pos = (x1, y2 + 10) if y1 < 50 else (x1, y1 - text_h - 10)\n",
    "        draw_text(draw, text_pos, label, font, color)\n",
    "\n",
    "    return img\n",
    "\n",
    "# ====== Main Execution ======\n",
    "with open(ANNOTATIONS_PATH) as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "healthy_keys = [k for k,v in annotations.items() if v['status'] == 'healthy']\n",
    "unhealthy_keys = [k for k,v in annotations.items() if v['status'] == 'unhealthy']\n",
    "\n",
    "sample_keys = []\n",
    "if healthy_keys:\n",
    "    sample_keys.append(random.choice(healthy_keys))\n",
    "if unhealthy_keys:\n",
    "    sample_keys.append(random.choice(unhealthy_keys))\n",
    "\n",
    "color_map = {}\n",
    "\n",
    "fig, axes = plt.subplots(1, len(sample_keys), figsize=FIG_SIZE)\n",
    "if len(sample_keys) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, key in enumerate(sample_keys):\n",
    "    ann = annotations[key]\n",
    "    img = visualize_sample(key, ann, color_map)\n",
    "    if img:\n",
    "        axes[i].imshow(img)\n",
    "        gd = ann.get('global_disease')\n",
    "        gd_text = ', '.join(gd) if gd else 'null'\n",
    "        axes[i].set_title(f\"ID: {key}\\nStatus: {ann['status']}\\nGlobal Disease: {gd_text}\", fontsize=16)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d2465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = None\n",
    "image_url = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225d73f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a serene natural landscape with a wooden boardwalk path cutting through a lush green field. The boardwalk leads the viewer's eye towards a line of trees in the distance under a bright blue sky dotted with scattered clouds. The vibrant green grass and the clear sky suggest a pleasant, sunny day, creating a peaceful and inviting scene.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  extra_headers={\n",
    "    \"HTTP-Referer\": \"<YOUR_SITE_URL>\", # Optional. Site URL for rankings on openrouter.ai.\n",
    "    \"X-Title\": \"<YOUR_SITE_NAME>\", # Optional. Site title for rankings on openrouter.ai.\n",
    "  },\n",
    "  extra_body={},\n",
    "  model=\"qwen/qwen2.5-vl-72b-instruct:free\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What is in this image?\"\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
