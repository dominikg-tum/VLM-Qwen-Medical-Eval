{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f42e0bb",
   "metadata": {},
   "source": [
    "# ðŸ« Qwen2.5 Chest X-ray Abnormality Grounding\n",
    "\n",
    "Locate abnormality areas in chest X-rays using Qwen2.5 and evaluate with mAP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0fbe7",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b286dd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the dataset: 50\n",
      "Number of images in the dataset: 50\n"
     ]
    }
   ],
   "source": [
    "import os, json, base64\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "def encode_image_to_data_uri(path: str) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "    return f\"data:image/png;base64,{b64}\"\n",
    "\n",
    "DATASET_DIR = \"VLM-Seminar25-Dataset/chest_xrays\"\n",
    "IMAGES_DIR = os.path.join(DATASET_DIR, \"images\")\n",
    "ANNOT_PATH = os.path.join(DATASET_DIR, \"annotations_len_50.json\")\n",
    "RESULTS_DIR = \"../results/chest_xrays/grounding\"\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "with open(ANNOT_PATH, \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "image_ids = list(annotations.keys())\n",
    "print(f\"Number of images in the dataset: {len(image_ids)}\")\n",
    "print(f\"Number of images in the dataset: {len(list(set(image_ids)))}\")\n",
    "\n",
    "load_dotenv(dotenv_path=\"../config/user.env\")\n",
    "api_key = os.environ.get(\"NEBIUS_API_KEY\")\n",
    "client = OpenAI(base_url=\"https://api.studio.nebius.com/v1/\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5caf2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_new_inference = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deba385",
   "metadata": {},
   "source": [
    "## 2. Model Inference\n",
    "Only done for unhealthy xrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8bbf658",
   "metadata": {},
   "outputs": [],
   "source": [
    "grounding_results = []\n",
    "if do_new_inference:\n",
    "    for img_id in tqdm(image_ids):\n",
    "        print()\n",
    "        ann = annotations[img_id]\n",
    "        if ann[\"status\"] == \"healthy\" or not ann.get(\"bbox_2d\") or ann.get(\"bbox_2d\") == []:\n",
    "            continue\n",
    "        # Get all unique diseases from bbox_2d (5th element in each box)\n",
    "        if ann[\"bbox_2d\"] < 5:\n",
    "            print(f\"Skipping {img_id} due to insufficient bbox_2d data.\")\n",
    "            continue\n",
    "        diseases_in_image = set([box[4] for box in ann[\"bbox_2d\"]])\n",
    "        for disease in diseases_in_image:\n",
    "            img_path = os.path.join(IMAGES_DIR, img_id + \".png\")\n",
    "            data_uri = encode_image_to_data_uri(img_path)\n",
    "            prompt = f\"Please locate {disease} and output bounding boxes as floats [x1, y1, x2, y2]. Output nothing else.\"\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"Qwen/Qwen2.5-VL-72B-Instruct\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": data_uri}},\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            pred = completion.choices[0].message.content.strip()\n",
    "            print(pred)\n",
    "            grounding_results.append({\"id\": img_id, \"disease\": disease, \"prediction\": pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d11ba76",
   "metadata": {},
   "source": [
    "Interesting prompting note: Without  \"If the disease is not present, output '[]'.\" it outputs coords, otherwise often not!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8954fc",
   "metadata": {},
   "source": [
    "## 3. Save Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730d4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved grounding results.\n"
     ]
    }
   ],
   "source": [
    "if do_new_inference:\n",
    "    with open(os.path.join(RESULTS_DIR, \"qwen2.5_grounding_results_per_disease.json\"), \"w\") as f:\n",
    "        json.dump(grounding_results, f, indent=2)\n",
    "    print(\"Saved grounding results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc176b1",
   "metadata": {},
   "source": [
    "**Or Load already given results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1eec9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of grounding results: 64\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(RESULTS_DIR, \"qwen2.5_grounding_results_per_disease.json\"), \"r\") as f:\n",
    "    grounding_results = json.load(f)\n",
    "print(f\"Number of grounding results: {len(grounding_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be09ef3",
   "metadata": {},
   "source": [
    "## 4. Evaluation & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "853202d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"eval_scripts\")\n",
    "from calculate_map import compute_map_supervision, draw_boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c47a822",
   "metadata": {},
   "source": [
    "### 4.1 Prepare Ground Truth and Predictions per Disease\n",
    "\n",
    "We will organize the ground truth and predicted bounding boxes per disease for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ground truth and predictions per disease and per image\n",
    "disease_set = set()\n",
    "true_boxes_per_img_disease = {}\n",
    "pred_boxes_per_img_disease = {}\n",
    "true_boxes_per_img = {}\n",
    "pred_boxes_per_img = {}\n",
    "\n",
    "# Collect all diseases\n",
    "for img_id, ann in annotations.items():\n",
    "    if ann.get(\"global_disease\"):\n",
    "        for disease in ann[\"global_disease\"]:\n",
    "            disease_set.add(disease)\n",
    "disease_list = sorted(list(disease_set))\n",
    "disease2id = {d: i for i, d in enumerate(disease_list)}\n",
    "\n",
    "# Ground truth per image/disease\n",
    "for img_id, ann in annotations.items():\n",
    "    if ann.get(\"global_disease\") and ann.get(\"boxes\"):\n",
    "        for disease, box in zip(ann[\"global_disease\"], ann[\"boxes\"]):\n",
    "            true_boxes_per_img_disease.setdefault((img_id, disease), []).append(box)\n",
    "            true_boxes_per_img.setdefault(img_id, []).append(box)\n",
    "\n",
    "# Predictions per image/disease\n",
    "for res in grounding_results:\n",
    "    img_id = res[\"id\"]\n",
    "    disease = res[\"disease\"]\n",
    "    try:\n",
    "        pred_boxes = json.loads(res[\"prediction\"])\n",
    "        if isinstance(pred_boxes[0], (int, float)):\n",
    "            pred_boxes = [pred_boxes]\n",
    "    except Exception:\n",
    "        pred_boxes = []\n",
    "    pred_boxes_per_img_disease.setdefault((img_id, disease), []).extend(pred_boxes)\n",
    "    pred_boxes_per_img.setdefault(img_id, []).extend(pred_boxes)\n",
    "\n",
    "print(f\"Diseases: {disease_list}\")\n",
    "print(f\"Example true boxes for first disease: {list(true_boxes_per_img_disease.items())[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077efb4",
   "metadata": {},
   "source": [
    "### 4.2 Compute mAP per Disease\n",
    "\n",
    "For each disease, we compute the mean Average Precision (mAP) across all images, considering only the bounding boxes and predictions for that disease. This helps to understand model performance for each abnormality type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17583b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mAP per disease\n",
    "disease_map_results = {}\n",
    "for disease in disease_list:\n",
    "    all_true_boxes = []\n",
    "    all_true_classes = []\n",
    "    all_pred_boxes = []\n",
    "    all_pred_classes = []\n",
    "    for img_id in image_ids:\n",
    "        # GT\n",
    "        gt_boxes = true_boxes_per_img_disease.get((img_id, disease), [])\n",
    "        all_true_boxes.extend(gt_boxes)\n",
    "        all_true_classes.extend([disease2id[disease]] * len(gt_boxes))\n",
    "        # Pred\n",
    "        pred_boxes = pred_boxes_per_img_disease.get((img_id, disease), [])\n",
    "        all_pred_boxes.extend(pred_boxes)\n",
    "        all_pred_classes.extend([disease2id[disease]] * len(pred_boxes))\n",
    "    result = compute_map_supervision(all_pred_boxes, all_pred_classes, all_true_boxes, all_true_classes)\n",
    "    disease_map_results[disease] = result.map\n",
    "    print(f\"mAP for {disease}: {result.map:.4f}\")\n",
    "\n",
    "# Save per-disease mAP\n",
    "with open(os.path.join(RESULTS_DIR, \"per_disease_map.json\"), \"w\") as f:\n",
    "    json.dump(disease_map_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a5c76",
   "metadata": {},
   "source": [
    "### 4.3 Compute Overall mAP\n",
    "\n",
    "Here, we compute the overall mean Average Precision (mAP) across all diseases and all images, providing a single summary metric for the model's localization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85659a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute overall mAP (all diseases, all images)\n",
    "all_true_boxes = []\n",
    "all_true_classes = []\n",
    "all_pred_boxes = []\n",
    "all_pred_classes = []\n",
    "for img_id in image_ids:\n",
    "    for disease in disease_list:\n",
    "        gt_boxes = true_boxes_per_img_disease.get((img_id, disease), [])\n",
    "        all_true_boxes.extend(gt_boxes)\n",
    "        all_true_classes.extend([disease2id[disease]] * len(gt_boxes))\n",
    "        pred_boxes = pred_boxes_per_img_disease.get((img_id, disease), [])\n",
    "        all_pred_boxes.extend(pred_boxes)\n",
    "        all_pred_classes.extend([disease2id[disease]] * len(pred_boxes))\n",
    "\n",
    "overall_result = compute_map_supervision(all_pred_boxes, all_pred_classes, all_true_boxes, all_true_classes)\n",
    "print(f\"Overall mAP: {overall_result.map:.4f}\")\n",
    "\n",
    "with open(os.path.join(RESULTS_DIR, \"overall_map.json\"), \"w\") as f:\n",
    "    json.dump({\"overall_map\": overall_result.map}, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcfe09e",
   "metadata": {},
   "source": [
    "### 4.4 Compute mAP per Image\n",
    "\n",
    "For each image, we compute the mAP considering all ground truth and predicted boxes (across all diseases) in that image. This helps to identify images where the model performs well or struggles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot mAP per image (all diseases in each image)\n",
    "per_image_map = {}\n",
    "for img_id in image_ids:\n",
    "    gt_boxes = true_boxes_per_img.get(img_id, [])\n",
    "    pred_boxes = pred_boxes_per_img.get(img_id, [])\n",
    "    # For classes, assign 0 to all (or use disease2id if you want to distinguish)\n",
    "    gt_classes = [0] * len(gt_boxes)\n",
    "    pred_classes = [0] * len(pred_boxes)\n",
    "    result = compute_map_supervision(pred_boxes, pred_classes, gt_boxes, gt_classes)\n",
    "    per_image_map[img_id] = result.map\n",
    "    print(f\"Image {img_id}: mAP = {result.map:.4f}\")\n",
    "    # Plot boxes for a few images\n",
    "    if len(gt_boxes) > 0 or len(pred_boxes) > 0:\n",
    "        print(f\"Plotting boxes for image {img_id}\")\n",
    "        draw_boxes(pred_boxes, gt_boxes)\n",
    "\n",
    "# Save per-image mAP\n",
    "with open(os.path.join(RESULTS_DIR, \"per_image_map.json\"), \"w\") as f:\n",
    "    json.dump(per_image_map, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359744d",
   "metadata": {},
   "source": [
    "### 4.4 Further mAP-based Analyses and Plots\n",
    "\n",
    "To further analyze model performance, consider:\n",
    "- Plotting mAP vs. disease frequency (how common each disease is in the dataset)\n",
    "- Plotting mAP vs. bounding box size (are small/large abnormalities harder to detect?)\n",
    "- Precision-Recall (PR) curves per disease\n",
    "- Confusion matrix for disease classification (if applicable)\n",
    "- Visualizing best/worst performing images or diseases\n",
    "- Analyzing mAP by image quality or other metadata\n",
    "\n",
    "These analyses can help identify strengths and weaknesses of the model and guide further improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4reg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
